---
title: A walkthrough of HTML scraping and regexes
---

Here's the religion-filtering-Texas-death-row script on a Gist:

<%=url_alone 'https://gist.github.com/dannguyen/b35713b4751272fc6346dc312f3cf470' %>


# Let's focus on last words of Texas death penalty inmates

The index page of offenders can be found here:

<%=url_alone 'https://www.tdcj.state.tx.us/death_row/dr_executed_offenders.html' %>

An individual inmate's last words page can be found here:

<%=url_alone 'https://www.tdcj.state.tx.us/death_row/dr_info/wardadamlast.html' %>

Who was Adam Ward? His biographical information is on a wholly separate page:

<%=url_alone 'https://www.tdcj.state.tx.us/death_row/dr_info/wardadam.html' %>


A simple task -- find out if Adam Ward was religious enough to mention religion in his last words, ends up being a microcosm of the pain and promise of web-scraping...or rather, being able to programmatically bring together data.


The site github repo has various files stashed away -- I'll link to them later:

<%=url_alone 'https://github.com/compjour/class-site-2016/tree/master/source/files/texas-death-penalty/code' %>




Some code to fetch and parse a single page:

~~~py
from bs4 import BeautifulSoup
import requests
SOURCE_URL = 'http://www.tdcj.state.tx.us/death_row/dr_info/wardadamlast.html'


resp = requests.get(SOURCE_URL)
soup = BeautifulSoup(resp.text, 'lxml')

# get the node with the Last Statement content
el = soup.find('p', text='Last Statement:')
# all other subsequent sibling nodes should have the right text
lastwords = ""
for p in el.find_next_siblings('p'):
    lastwords += p.text

# All done with extracting last words...let's try to get their name
offel = soup.find('p', text="Offender:")
# by definition, the next sibling p tag contains the name
offender = offel.find_next_sibling('p').text

print(offender)
print(lastwords)
~~~
